{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a8E7De68YVps",
      "metadata": {
        "id": "a8E7De68YVps"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "Travail individuel à réaliser par chaque étudiant. Chaque fichier devra ensuite être rassemblé par groupe dans le premier dépôt Git de l'année universitaire, dans un nouveau dossier nommé <code>Computer Vision</code>.\n",
        "\n",
        "Le nom du fichier doit être le prénom de l'étudiant écrit en minuscules. Par exemple, si l'étudiant s'appelle BOB Toto, le fichier doit être nommé toto.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K6EHkj63XsUy",
      "metadata": {
        "id": "K6EHkj63XsUy"
      },
      "source": [
        "# Détails de l'étudiant\n",
        "### Nom(s)  : RABE ANDRIANAOSLO\n",
        "### Prénom(s) : Johaninho Nirinjaka\n",
        "### Classe : IGGLIA 4 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Vision par Ordinateur avec Keras/TensorFlow : Un Notebook Pratique et Conceptuel\n",
        "\n",
        "Ce notebook a pour objectif de vous guider pas à pas dans la création et l'analyse d'un modèle de réseau de neurones convolutif (CNN) appliqué au jeu de données CIFAR-10. Chaque étape est accompagnée d'explications pratiques ainsi que de questions conceptuelles pour renforcer votre compréhension des enjeux théoriques et pratiques de la vision par ordinateur."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape1",
      "metadata": {
        "id": "etape1"
      },
      "source": [
        "## Étape 1 : Introduction et Configuration de l'Environnement\n",
        "\n",
        "Dans cette étape, nous allons configurer notre environnement de travail et importer les bibliothèques indispensables pour le deep learning et la manipulation de données. Nous vérifions également la version de TensorFlow pour nous assurer que tout fonctionne correctement.\n",
        "\n",
        "### Explication Pratique\n",
        "La bonne configuration de l'environnement est cruciale pour garantir la reproductibilité et la stabilité de vos expériences. En particulier, les versions des bibliothèques peuvent influencer le comportement du modèle et sa performance, d'où l'importance de vérifier et documenter ces versions dès le début."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "code-etape1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code-etape1",
        "outputId": "bb1339f0-25eb-4422-af7b-15b5088ed18a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Version de TensorFlow : 2.18.0\n"
          ]
        }
      ],
      "source": [
        "# Importer les bibliothèques nécessaires\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Version de TensorFlow :', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question1",
      "metadata": {
        "id": "question1"
      },
      "source": [
        "### Question  1\n",
        "\n",
        "**Q1 :** Pourquoi est-il essentiel de vérifier la configuration de l'environnement (versions des bibliothèques, dépendances, etc.) avant de développer un modèle de deep learning ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36aeb690",
      "metadata": {},
      "source": [
        "### Réponse Q1\n",
        "Il est essentiel de vérifier la configuration de l’environnement (versions des bibliothèques, dépendances, etc.) avant de développer un modèle de deep learning pour plusieurs raisons :\n",
        "\n",
        "- **Reproductibilité des résultats** : En deep learning, même une légère différence de version dans une bibliothèque comme TensorFlow ou PyTorch peut modifier les résultats obtenus. Documenter les versions permet de garantir que le modèle peut être reproduit avec les mêmes performances sur un autre système.\n",
        "\n",
        "- **Compatibilité des dépendances** : Certaines versions de bibliothèques peuvent être incompatibles entre elles. Vérifier ces compatibilités évite des erreurs difficiles à diagnostiquer.\n",
        "\n",
        "- **Optimisation des performances** : Les mises à jour de bibliothèques apportent souvent des améliorations en termes de performance et de gestion de la mémoire. Cependant, elles peuvent aussi introduire des changements affectant le comportement des modèles. Tester une version spécifique garantit que l’environnement est optimisé pour l’application cible.\n",
        "\n",
        "- **Facilitation du déploiement** : Lors du passage du développement à la production, disposer d’un environnement bien défini (souvent via des fichiers comme requirements.txt ou environment.yml) permet d’éviter des problèmes liés aux mises à jour inattendues de bibliothèques.\n",
        "\n",
        "En résumé, la vérification de l’environnement assure un développement stable, prévisible et reproductible, ce qui est essentiel pour des projets de deep learning fiables et performants."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape2",
      "metadata": {
        "id": "etape2"
      },
      "source": [
        "## Étape 2 : Chargement et Prétraitement des Données\n",
        "\n",
        "Nous allons charger le jeu de données CIFAR-10, composé de 60 000 images couleur réparties en 10 classes. Dans cette étape, nous normalisons les valeurs des pixels afin qu'elles soient comprises entre 0 et 1, et nous transformons les étiquettes en format one-hot pour faciliter le processus de classification.\n",
        "\n",
        "### Explication Pratique\n",
        "La normalisation aide à stabiliser et accélérer l'entraînement du modèle en assurant que les valeurs d'entrée ont une échelle comparable. Le one-hot encoding évite que le modèle interprète les étiquettes comme des valeurs numériques ordonnées, ce qui est essentiel pour les problèmes de classification multi-classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape2",
      "metadata": {
        "id": "code-etape2"
      },
      "outputs": [],
      "source": [
        "# Charger le jeu de données CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normaliser les valeurs des pixels (entre 0 et 1)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convertir les vecteurs de classes en matrices binaires (one-hot encoding)\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        " \n",
        "print(\"Forme des données d'entrainement :\", x_train.shape)\n",
        "print(\"Forme des étiquettes d'entraînement :\", y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question2",
      "metadata": {
        "id": "question2"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "**Q2 :** Expliquez comment la normalisation des pixels et le one-hot encoding des étiquettes contribuent chacun à la stabilité et à l'efficacité de l'entraînement d'un modèle de deep learning.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48fdb3d6",
      "metadata": {},
      "source": [
        "### Réponse Q2\n",
        "\n",
        "La normalisation des pixels et le one-hot encoding des étiquettes sont deux étapes qui facilitent l’apprentissage du modèle et améliorent ses performances.\n",
        "\n",
        "**Pourquoi normaliser les pixels ?** \n",
        "Les images sont constituées de pixels dont les valeurs varient entre 0 et 255. Si on les garde sous cette forme, certaines valeurs seront très élevées et d’autres très faibles, ce qui peut déséquilibrer l’apprentissage du modèle. En divisant chaque pixel par 255 pour ramener les valeurs entre 0 et 1, on uniformise les données. Cela permet :\n",
        "\n",
        "- Un entraînement plus stable,\n",
        "\n",
        "- Une convergence plus rapide,\n",
        "\n",
        "- Une meilleure gestion des calculs, en évitant des problèmes liés aux gradients trop grands ou trop petits.\n",
        "\n",
        "**Pourquoi utiliser le one-hot encoding ?** \n",
        "Les étiquettes des images sont souvent représentées par des nombres (par exemple : 0 pour \"chat\", 1 pour \"chien\", 2 pour \"voiture\"). Le problème, c’est que le modèle pourrait croire qu’il existe un ordre entre ces classes, ce qui n’est pas le cas. Pour éviter cette confusion, on transforme chaque étiquette en un vecteur où seule la case correspondant à la classe est activée. Par exemple :\n",
        "\n",
        "- \"Chat\" devient [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "- \"Chien\" devient [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "Grâce à cette transformation, le modèle comprend que chaque classe est indépendante des autres et ne fait pas de liens erronés entre elles.\n",
        "\n",
        "\n",
        "La normalisation aide le modèle à mieux gérer les données et accélère son apprentissage. Le one-hot encoding empêche toute confusion sur les relations entre les classes. Ces deux étapes permettent d’obtenir un entraînement plus efficace et plus fiable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape3",
      "metadata": {
        "id": "etape3"
      },
      "source": [
        "## Étape 3 : Exploration et Visualisation des Données\n",
        "\n",
        "Avant de construire le modèle, il est important d'explorer et de visualiser les données. Nous affichons ainsi un échantillon d'images du jeu de données pour mieux comprendre leur contenu et la distribution des classes.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation des données permet d'identifier d'éventuelles anomalies, comme des classes sous-représentées ou des images bruitées, et de décider si des techniques d'augmentation de données ou de prétraitement supplémentaires sont nécessaires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape3",
      "metadata": {
        "id": "code-etape3"
      },
      "outputs": [],
      "source": [
        "# Afficher quelques images du jeu de données d'entraînement\n",
        "noms_classes = ['avion', 'automobile', 'oiseau', 'chat', 'cerf',\n",
        "               'chien', 'grenouille', 'cheval', 'navire', 'camion']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.xlabel(noms_classes[y_train[i].argmax()])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question3",
      "metadata": {
        "id": "question3"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "**Q3 :** D'après la visualisation, discutez de l'impact potentiel d'une distribution inégale des classes ou de la présence d'images de mauvaise qualité sur la performance d'un modèle de classification. Quelles stratégies pourraient être mises en place pour pallier ces problèmes ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51cc4ee4",
      "metadata": {},
      "source": [
        "### Réponse Q3\n",
        "\n",
        "Une distribution inégale des classes peut entraîner un biais du modèle, qui aura tendance à mieux reconnaître les classes majoritaires et à sous-performer sur les classes rares. De même, la présence d’images bruitées ou mal annotées peut perturber l’apprentissage, en rendant plus difficile l’extraction de caractéristiques pertinentes. Ces problèmes peuvent réduire la capacité du modèle à bien généraliser et affecter sa précision globale.\n",
        "\n",
        "Pour atténuer ces effets, plusieurs stratégies peuvent être mises en place : le sur-échantillonnage des classes sous-représentées, le sous-échantillonnage des classes dominantes, ou l’ajustement de la fonction de perte pour mieux équilibrer l’apprentissage. Il est aussi crucial d’améliorer la qualité des données en supprimant ou corrigeant les images bruitées et en utilisant des techniques d’augmentation de données pour renforcer la robustesse du modèle.\n",
        "\n",
        "En résumé, explorer et visualiser les données permet d’identifier ces déséquilibres et anomalies à temps, afin d’appliquer des correctifs adaptés. Un jeu de données propre et bien réparti est essentiel pour garantir une classification plus précise et efficace."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape4",
      "metadata": {
        "id": "etape4"
      },
      "source": [
        "## Étape 4 : Construction du Modèle CNN\n",
        "\n",
        "Nous allons construire un réseau de neurones convolutif (CNN) pour extraire des caractéristiques hiérarchiques des images. Ce modèle se compose de plusieurs blocs de convolution suivis de couches de pooling et se termine par des couches entièrement connectées pour la classification.\n",
        "\n",
        "### Explication Pratique\n",
        "Les couches de convolution permettent au modèle de détecter des motifs locaux (comme les contours ou les textures), tandis que les couches de pooling réduisent la dimensionnalité, ce qui diminue la charge computationnelle et aide à rendre le modèle plus robuste aux translations. Le dropout, quant à lui, est une technique de régularisation qui aide à prévenir le surapprentissage en désactivant aléatoirement certains neurones pendant l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape4",
      "metadata": {
        "id": "code-etape4"
      },
      "outputs": [],
      "source": [
        "# Construire le modèle CNN\n",
        "model = models.Sequential()\n",
        "\n",
        "# Bloc de convolution 1 : 32 filtres, taille 3x3, activation ReLU\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 2 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 3 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Aplatir les sorties et ajouter des couches entièrement connectées\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question4",
      "metadata": {
        "id": "question4"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "**Q4 :** Décrivez le rôle de chaque composant du CNN (couches de convolution, pooling et dropout) et expliquez comment ils interagissent pour permettre au modèle d'extraire des caractéristiques pertinentes des images.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d2b5b84",
      "metadata": {},
      "source": [
        "### Réponse Q4\n",
        "\n",
        "Les couches de convolution sont essentielles dans un CNN, car elles permettent d’extraire automatiquement des motifs visuels à différents niveaux. Les premiers filtres détectent des formes simples comme les contours, tandis que les couches plus profondes captent des structures plus complexes comme des textures ou des objets entiers. Chaque neurone d’une couche de convolution ne traite qu’une petite région de l’image, ce qui permet au modèle d’analyser les motifs localement avant de les combiner pour une compréhension globale.\n",
        "\n",
        "Les couches de pooling, souvent basées sur le max-pooling, réduisent la dimensionnalité des données en ne conservant que les informations les plus importantes. Cela permet de diminuer la charge computationnelle, d’accélérer l’apprentissage et de rendre le modèle plus robuste aux variations dans l’image (comme les décalages ou les légères déformations). Enfin, la couche de dropout joue un rôle clé dans la régularisation en désactivant aléatoirement certains neurones lors de l'entraînement. Cela empêche le modèle de trop s’adapter aux données d’apprentissage et améliore sa capacité à généraliser sur de nouvelles images.\n",
        "\n",
        "En combinant ces éléments, le CNN apprend progressivement à détecter des caractéristiques de plus en plus complexes, tout en maintenant un bon équilibre entre performance et généralisation. Les couches de convolution extraient les motifs, le pooling simplifie l’information et le dropout évite le surapprentissage, garantissant ainsi un modèle efficace et robuste."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape5",
      "metadata": {
        "id": "etape5"
      },
      "source": [
        "## Étape 5 : Compilation et Entraînement du Modèle\n",
        "\n",
        "Nous allons maintenant compiler le modèle en choisissant un optimiseur, une fonction de perte ainsi que des métriques d'évaluation. Ensuite, nous entraînons le modèle sur les données d'entraînement en réservant une partie des données pour la validation.\n",
        "\n",
        "### Explication Pratique\n",
        "La compilation configure le processus d'apprentissage, notamment la manière dont les poids seront ajustés via la rétropropagation. Le choix de l'optimiseur (ici, Adam) et la définition des hyperparamètres (comme le taux d'apprentissage et la taille du batch) influencent grandement la vitesse de convergence et la qualité finale du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape5",
      "metadata": {
        "id": "code-etape5"
      },
      "outputs": [],
      "source": [
        "# Compiler le modèle\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question5",
      "metadata": {
        "id": "question5"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "**Q5 :** Quels sont les effets d'un choix inadapté d'hyperparamètres (comme le taux d'apprentissage ou la taille du batch) sur l'entraînement d'un réseau de neurones ? Expliquez en quoi un optimiseur bien configuré est crucial pour la convergence du modèle.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55069325",
      "metadata": {},
      "source": [
        "### Réponse Q5\n",
        "\n",
        "Un choix inadapté des hyperparamètres peut avoir un impact négatif sur l'entraînement d'un réseau de neurones. Un taux d’apprentissage trop élevé peut empêcher le modèle de converger, car les mises à jour des poids seront trop brutales, risquant de sauter les solutions optimales. À l’inverse, un taux trop faible ralentit l’apprentissage et peut coincer le modèle dans un minimum local. De même, une taille de batch trop grande peut entraîner une convergence plus rapide mais moins généralisable, tandis qu’une taille trop petite peut rendre l’optimisation instable et plus sujette aux variations aléatoires.\n",
        "\n",
        "L’optimiseur joue un rôle clé dans la convergence du modèle. Par exemple, Adam combine les avantages de la descente de gradient classique et de l’optimisation adaptative, permettant un ajustement efficace des poids même sur des ensembles de données complexes. Un optimiseur mal configuré peut ralentir l’apprentissage ou conduire à des performances médiocres. Une bonne combinaison d’hyperparamètres et d’un optimiseur bien choisi assure une convergence rapide et stable, tout en améliorant la capacité du modèle à bien généraliser sur de nouvelles données."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape6",
      "metadata": {
        "id": "etape6"
      },
      "source": [
        "## Étape 6 : Évaluation du Modèle\n",
        "\n",
        "Après l'entraînement, nous évaluons notre modèle sur le jeu de test afin de mesurer sa capacité de généralisation sur des données inédites. Les métriques telles que la perte et la précision nous aident à quantifier la performance globale du modèle.\n",
        "\n",
        "### Explication Pratique\n",
        "L'évaluation sur un jeu de test indépendant permet de détecter un éventuel surapprentissage (overfitting). Si le modèle présente une bonne performance sur l'entraînement mais une performance médiocre sur le test, cela indique qu'il n'a pas suffisamment généralisé, ce qui peut nécessiter des ajustements comme plus de régularisation ou des techniques d'augmentation de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape6",
      "metadata": {
        "id": "code-etape6"
      },
      "outputs": [],
      "source": [
        "# Évaluer le modèle sur le jeu de test\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Précision sur le jeu de test :', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question6",
      "metadata": {
        "id": "question6"
      },
      "source": [
        "### Question  6\n",
        "\n",
        "**Q6 :** Que nous indiquent la perte et la précision obtenues lors de l'évaluation sur le jeu de test ? Quels ajustements pourriez-vous envisager si vous observez un écart significatif entre les performances sur l'entraînement et le test ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d4515ff",
      "metadata": {},
      "source": [
        "### Réponse Q6\n",
        "\n",
        "La perte et la précision obtenues lors de l’évaluation sur le jeu de test permettent de mesurer la capacité du modèle à généraliser sur des données inédites. Une faible perte et une haute précision indiquent un bon apprentissage, tandis qu’un écart significatif entre les performances sur l'entraînement et le test peut signaler un problème de surapprentissage (overfitting). Dans ce cas, le modèle a mémorisé les données d’entraînement au lieu d’apprendre des motifs généralisables, ce qui le rend inefficace sur de nouvelles données."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape7",
      "metadata": {
        "id": "etape7"
      },
      "source": [
        "## Étape 7 : Prédictions et Visualisation des Résultats\n",
        "\n",
        "Nous allons utiliser le modèle entraîné pour prédire les classes des images du jeu de test. La visualisation des résultats nous permet de comparer les étiquettes prédites aux étiquettes réelles et d'identifier les erreurs potentielles.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation aide à comprendre qualitativement comment le modèle se comporte face à différentes images. Cela permet d'identifier si certaines classes sont systématiquement mal prédites ou si le modèle confond certaines catégories, ouvrant ainsi la voie à des améliorations ultérieures (par exemple, via l'augmentation de données ou des ajustements de l'architecture)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape7",
      "metadata": {
        "id": "code-etape7"
      },
      "outputs": [],
      "source": [
        "# Faire des prédictions sur le jeu de test\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Fonction pour afficher l'image avec les étiquettes prédites et réelles\n",
        "def afficher_image(i, predictions_array, etiquette_vraie, img):\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    etiquette_predite = np.argmax(predictions_array)\n",
        "    etiquette_vraie = np.argmax(etiquette_vraie)\n",
        "\n",
        "    couleur = 'blue' if etiquette_predite == etiquette_vraie else 'red'\n",
        "    plt.xlabel(f\"Prédit : {noms_classes[etiquette_predite]} (Vrai : {noms_classes[etiquette_vraie]})\", color=couleur)\n",
        "\n",
        "# Afficher quelques images de test avec leurs prédictions\n",
        "nb_lignes = 5\n",
        "nb_colonnes = 3\n",
        "nb_images = nb_lignes * nb_colonnes\n",
        "plt.figure(figsize=(2 * nb_colonnes, 2 * nb_lignes))\n",
        "for i in range(nb_images):\n",
        "    plt.subplot(nb_lignes, nb_colonnes, i+1)\n",
        "    afficher_image(i, predictions[i], y_test[i], x_test[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question7",
      "metadata": {
        "id": "question7"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "**Q7 :** Après avoir examiné les prédictions, identifiez et discutez des stratégies conceptuelles (par exemple, l'augmentation de données, le raffinement de l'architecture ou l'ajustement des hyperparamètres) qui pourraient améliorer la robustesse et la précision du modèle.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7adcb363",
      "metadata": {},
      "source": [
        "### Réponse Q7\n",
        "L’analyse des prédictions permet d’identifier les classes mal reconnues et les motifs d’erreur du modèle. Si certaines classes sont systématiquement confondues, cela peut indiquer un manque de diversité dans les données d’entraînement ou des caractéristiques trop similaires entre certaines catégories. Une solution efficace est l’augmentation de données, qui enrichit le jeu d’entraînement en appliquant des transformations comme la rotation, le changement de luminosité ou le recadrage, aidant ainsi le modèle à mieux généraliser.\n",
        "\n",
        "Un autre levier d’amélioration est le raffinement de l’architecture du réseau. Ajouter des couches de convolution ou modifier la fonction d’activation peut permettre une extraction de caractéristiques plus fine. Enfin, l’ajustement des hyperparamètres, comme la modification du taux d’apprentissage ou l’optimisation du dropout, peut améliorer la convergence et la robustesse du modèle. Ces stratégies combinées permettent de renforcer la précision et de rendre le modèle plus performant sur des images inédites."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape8",
      "metadata": {
        "id": "etape8"
      },
      "source": [
        "## Étape 8 : Conclusion et Travaux Futurs\n",
        "\n",
        "Dans ce notebook, nous avons :\n",
        "- Configuré l'environnement et importé les bibliothèques nécessaires\n",
        "- Chargé et prétraité le jeu de données CIFAR-10\n",
        "- Exploré et visualisé les données\n",
        "- Construit, compilé et entraîné un modèle CNN\n",
        "- Évalué le modèle et visualisé ses prédictions\n",
        "\n",
        "### Explication Pratique\n",
        "Ce pipeline offre une approche complète, à la fois pratique et conceptuelle, pour la mise en œuvre d'un modèle de vision par ordinateur. Pour aller plus loin, vous pouvez explorer des architectures plus complexes, appliquer des techniques d'augmentation de données ou encore expérimenter avec différents optimisateurs afin de mieux comprendre l'impact de chacun sur la performance du modèle."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
